‚úÖ What is MongoDB?
MongoDB is a NoSQL document-based database. 
It stores data in flexible, JSON-like documents (BSON) instead of rows and tables like in relational databases.

// list databases
show dbs

// Create or switch to DB
use database_name

// list collections
show collections

db.users.insertOne({ name: "abhishek", age: 26 });
db.users.find();
db.users.findOne({_id: ObjectId("684db80062d2eee7c5782ae4")});
db.users.update({ _id: ObjectId("684db80062d2eee7c5782ae4") }, { $set: { age: 27 } });
db.users.deleteOne({ _id: ObjectId("684db80062d2eee7c5782ae4") })

üîç Part 2: Data Types & Document Structure (BSON)
MongoDB uses BSON (Binary JSON) under the hood ‚Äî this adds data types not present in regular JSON
| Type       | Example                                     | Notes                  |
| ---------- | ------------------------------------------- | ---------------------- |
| `String`   | `"Abhishek"`                                | Most common            |
| `Number`   | `NumberInt(26)`, `NumberLong(123456789012)` | Use right size         |
| `Boolean`  | `true`, `false`                             | Logical checks         |
| `Date`     | `ISODate("2024-06-14T10:00:00Z")`           | Default for timestamps |
| `Array`    | `[1, 2, 3]`                                 | Useful for tags, lists |
| `Object`   | `{ address: { city: "Mumbai" }}`            | Nested data            |
| `ObjectId` | `ObjectId("507f1f77bcf86cd799439011")`      | Auto `_id`             |
| `Null`     | `null`                                      | For optional fields    |

db.users.insertOne({
    name: "Abhishek",
    age: 26,
    is_active: true,
    hobbies: ["coding", "music"],
    address: {
        street: "test street",
        pincode: 421003,
    },
    created_by: null,
    created_at: new Date(),
});


üèóÔ∏è Part 3: Schema Design in MongoDB
Unlike SQL, MongoDB is schema-less, but that doesn't mean unstructured.

üî∏ Two ways to model relations:
| Approach        | When to Use                                      | Example                             |
| --------------- | ------------------------------------------------ | ----------------------------------- |
| **Embedding**   | 1:1, 1\:many with tight coupling                 | User with embedded address          |
| **Referencing** | many\:many, large or frequently updated sub-docs | User and separate Orders collection |

üß† Best Practices for Schema Design:
1. Use embedding for high read speed if related data is always fetched together.
2. Use referencing for large or changing datasets.
3. Keep document size under 16MB limit.
4. Don‚Äôt over-nest ‚Äî limit nesting to ~3 levels deep.

db.authors.insert(
    [
        {
            name: "Abhishek",
            email: "abhishek@email.com",
            bio: "test bio1",
        },
        {
            name: "Hansraj",
            email: "hansraj@email.com",
            bio: "test bio2",
        }
    ]
);

db.posts.insert({
    title: "Learning MongoDB",
    content: "Lorem ipsum test 1",
    tags: ["db", "mongo"],
    author_id: ObjectId("684dbc09eabc96db8f010a5a"),
    created_at: new Date(),
});
db.posts.insert({
    title: "Learning Nodejs",
    content: "Lorem ipsum test 2",
    tags: ["nodejs", "javascript"],
    author_id: ObjectId("684dbc09eabc96db8f010a5a"),
    created_at: new Date(),
});
db.posts.insert({
    title: "Learning Javascript",
    content: "Lorem ipsum test 3",
    tags: ["javascript"],
    author_id: ObjectId("684dbc09eabc96db8f010a5b"),
    created_at: new Date(),
});

‚ö°Ô∏è Part 4: Indexing & Query Optimization
In MongoDB, indexes are absolutely essential for high-performance queries ‚Äî especially as your dataset grows.

üß† Why Use Indexes?
Without indexes, MongoDB does a collection scan (scans every document).
With indexes:
    1. Queries are faster üöÄ
    2. Sorts are faster
    3. Uniqueness can be enforced

üìå Default Index: _id
Every collection automatically has an index on _id.

You can also add custom indexes:
db.posts.createIndex({ author_id: 1 });
db.posts.createIndex({ tags: 1 });
db.posts.createIndex({ title: "text" }); // for text search

üìê Compound Indexes
You can index on multiple fields:
db.posts.createIndex({ author_id: 1, created_at: -1 });

Use compound indexes when you often filter/sort on multiple fields together.

üß† Rule: MongoDB can use prefixes of compound indexes.
| Index Created           | Queries Supported              |
| ----------------------- | ------------------------------ |
| `{ a: 1, b: -1, c: 1 }` | ‚úÖ `{ a: 1 }`, `{ a: 1, b: 1 }` |
|                         | ‚ùå `{ b: 1 }`, `{ c: 1 }`       |



db.posts.find({ tags: "javascript" }).explain("executionStats");

üîé .explain() - gives you how MongoDB plans and executes a query
There are 3 modes:
    1. "queryPlanner" ‚Äì shows the plan without running the query.
    2. "executionStats" ‚Äì runs the query and shows performance stats.
    3. "allPlansExecution" ‚Äì shows stats for all plans considered (used in complex queries).

üß™ Try This:
1. Run the find query before indexing on tags.
2. Then run: db.posts.createIndex({ tags: 1 });
3. Run the same query after indexing and use .explain("executionStats") again.
‚û°Ô∏è You should see:
    1. stage changes from "COLLSCAN" to "IXSCAN"
    2. totalDocsExamined drops drastically
    3. executionTimeMillis reduces


üèóÔ∏è Part 5: Aggregation Framework
MongoDB‚Äôs most powerful feature for analytics, transformations, joins, grouping, and more. It's like SQL‚Äôs GROUP BY, JOIN, ORDER BY, WHERE, etc., all combined in a super flexible pipeline format.

Aggregation in MongoDB is based on pipelines. You take documents from a collection, then pass them through a sequence of stages, each transforming the data.
db.collection.aggregate([
  { $match: { ... } },
  { $group: { _id: ..., total: { $sum: ... } } },
  { $sort: { ... } }
])
Each stage receives input documents and outputs transformed documents.

| Stage      | Description                           |
| ---------- | ------------------------------------- |
| `$match`   | Filters documents (like `find`)       |
| `$project` | Reshapes documents (select fields)    |
| `$group`   | Groups documents, like SQL `GROUP BY` |
| `$sort`    | Sorts documents                       |
| `$limit`   | Limits number of output documents     |
| `$skip`    | Skips a number of documents           |
| `$lookup`  | Performs a JOIN                       |
| `$unwind`  | Deconstructs an array field           |
| `$count`   | Counts documents                      |

‚úÖ Example 1: Count posts per author
db.posts.aggregate([
    {
        $group: {
            _id: "$author_id",
            totalPosts: { $sum: 1 } 
        }
    }
])
// result -----
[
  { _id: ObjectId('684dbc09eabc96db8f010a5a'), totalPosts: 2 },
  { _id: ObjectId('684dbc09eabc96db8f010a5b'), totalPosts: 1 }
]

‚úÖ Example 2: Get latest 2 posts with only title and author
db.posts.aggregate([
    {
        $sort: { created_at: - 1 }
    },
    {
        $limit: 2,
    },
    {
        $project: { title: 1, author_id: 1, _id: 0 }
    }
])
// result -----
[
  {
    title: 'Learning Javascript',
    author_id: ObjectId('684dbc09eabc96db8f010a5b')
  },
  {
    title: 'Learning Nodejs',
    author_id: ObjectId('684dbc09eabc96db8f010a5a')
  }
]

‚úÖ Example 3: Join posts with author name ($lookup)
db.posts.aggregate([
    {
        $lookup: {
            from: "authors",
            localField: "author_id",
            foreignField: "_id",
            as: "author"
        }
    },
    { $unwind: "$author" },
    {
        $project: {
            title: 1,
            authorName: "$author.name",
            created_at: 1,
        }
    }
])
// result -----
[
  {
    _id: ObjectId('684dbc98eabc96db8f010a5c'),
    title: 'Learning MongoDB',
    created_at: ISODate('2025-06-14T18:16:56.713Z'),
    authorName: 'Abhishek'
  },
  {
    _id: ObjectId('684dbcbaeabc96db8f010a5d'),
    title: 'Learning Nodejs',
    created_at: ISODate('2025-06-14T18:17:30.853Z'),
    authorName: 'Abhishek'
  },
  {
    _id: ObjectId('684dbcd7eabc96db8f010a5e'),
    title: 'Learning Javascript',
    created_at: ISODate('2025-06-14T18:17:59.211Z'),
    authorName: 'Hansraj'
  }
]

üß® Part 6A: $unwind ‚Äì Flattening Arrays
‚úÖ What does $unwind do?
It deconstructs an array field from a document and outputs a document for each element in the array.

üéØ Why use it?
    1. For aggregation on individual array elements
    2. To apply filters or counts on items inside arrays

üì¶ Example Document:
{
  title: "Learning Nodejs",
  tags: ["nodejs", "javascript", "backend"]
}

// this will deconstruct the tags array
db.posts.aggregate([{$unwind: "$tags"}]);
// result
[
    {
        title: "Learning Nodejs",
        tags: "nodejs"
    },
    {
        title: "Learning Nodejs",
        tags: "javascript"
    },
    {
        title: "Learning Nodejs",
        tags: "backend"
    },
]


// Count posts tagged with "javascript"
db.posts.aggregate([
    {
        $unwind: "$tags"
    },
    {
        $match: {
            tags: { $in: ["javascript"] }
        }
    },
    {
        $group: {
            _id: "$tags",
            totalPosts: { $sum: 1 }
        }
    }
])

üîç What is Full-Text Search?
Full-text search allows you to search for words or phrases inside text fields (like titles, content, descriptions, etc.). 
It‚Äôs similar to how search engines work.

‚öôÔ∏è How MongoDB Supports Full-Text Search
MongoDB supports basic full-text search using text indexes. 
When you create a text index on a field, MongoDB:\
    1. Tokenizes the text (splits into words),
    2. Converts to lowercase,
    3. Ignores stop words (like "the", "a", "is", etc.),
    4. Creates an inverted index for efficient lookup.

‚úÖ Step 1: Create a Collection with Text
db.articles.insertMany([
  {
    title: "Learning MongoDB",
    content: "MongoDB is a NoSQL database that supports full-text search."
  },
  {
    title: "Getting Started with Node.js",
    content: "Node.js allows you to build scalable backend services."
  }
])

‚úÖ Step 2: Create a Text Index
You can create a text index on one or multiple fields.
db.articles.createIndex({ content: "text" });
db.articles.createIndex({ title: "text", content: "text" });

NOTE: üß† Important: You can only have one text index per collection.

‚úÖ Step 3: Perform a Text Search
db.articles.find({ $text: { $search: "mongodb" } });
This will return documents where any of the indexed fields contain the word "mongodb".

üéØ Searching Multiple Terms
üîπ Any of the words:
db.articles.find({ $text: { $search: "mongodb nodejs" } });
Matches articles that contain either word.

üîπ Exact phrase:
db.articles.find({ $text: { $search: "\"text search\"" } });
Use double quotes for exact phrases.

db.posts.find(
    {
        $text: {
            $search: "mongodb"
        }
    },
)
This performs a text search for the word "mongodb" in fields that are part of a text index.

// we have another query here
db.posts.find(
    {
        $text: {
            $search: "mongodb"
        }
    },
    { score: { $meta: "textScore" }, title: 1 }
)
This is the projection (what fields to return):
    1. score: { $meta: "textScore" }: includes the relevance score calculated by MongoDB.
    2. title: 1: includes the title field
    3. All other fields are excluded by default.

documents most closely matching will have higher text relevance score
[
  { "title": "Getting started with MongoDB", "score": 3.5 },
  { "title": "Advanced MongoDB features", "score": 2.1 }
]

üîê Part 7: MongoDB Transactions & ACID
MongoDB started as a flexible NoSQL DB, but now supports multi-document transactions, making it reliable for critical business operations, just like relational databases.

üß† What Is a Transaction?
A transaction is a sequence of database operations that are treated as a single unit:
    1. Either all operations succeed (COMMIT),
    2. Or none of them do (ROLLBACK).

‚úÖ MongoDB and ACID
MongoDB now fully supports ACID guarantees in transactions:
| Term        | Meaning                                          |
| ----------- | ------------------------------------------------ |
| Atomicity   | All operations succeed or fail as a whole        |
| Consistency | Ensures data remains valid after the transaction |
| Isolation   | Concurrent transactions don‚Äôt interfere          |
| Durability  | Once committed, data stays even after crash      |


üîß Basic Syntax of a Transaction
const session = db.getMongo().startSession();
const postsCollection = session.getDatabase("test").posts;
const authorsCollection = session.getDatabase("test").authors;

session.startTransaction();

try {
  postsCollection.insertOne({
    title: "New Post inside TX",
    author_id: ObjectId("684dbc09eabc96db8f010a5a"),
    created_at: new Date()
  });

  authorsCollection.updateOne(
    { _id: ObjectId("...") },
    { $set: { bio: "Updated inside transaction" } }
  );

  session.commitTransaction();
  print("Transaction committed.");
} catch (e) {
  session.abortTransaction();
  print("Transaction aborted due to error:", e);
}

‚ùó WARNING
If you try to run a transaction on a standalone MongoDB instance, which does not support transactions.
You will see this error,
MongoServerError[IllegalOperation]: Transaction numbers are only allowed on a replica set member or mongos

‚ùó Why This Error Occurs
Multi-document transactions in MongoDB are only supported on:
    1. Replica sets
    2. Sharded clusters (via mongos)
Standalone servers (e.g., what you get from a default local install or Docker without replica set config) do not support transactions and will throw this error when you try.

‚úÖ How to Fix It
You need to run MongoDB as a replica set, even if it's a single-node setup (for dev/test purposes).

üîß Option A: Start MongoDB as a Single-Node Replica Set
1. Stop your running MongoDB (if any).
2. Start it with replica set config, for example:
    mongod --replSet rs0 --port 27017 --dbpath /your/db/path
3. In a new shell, initiate the replica set:
    mongosh
    > rs.initiate()
You‚Äôll now be running a single-node replica set, suitable for local testing with transactions.

üîÅ Want Transactions? Use Replica Set

Transactions need a replica set. Here's how to start a container that supports this:
Step 1: Run MongoDB with a replica set name
    docker run -d --name mongo-rs -p 27017:27017 -v ./mongo-rs-data:/data/db mongo:7.0 --replSet rs0
Step 2: Initiate the Replica Set - Once the container is running, connect using mongosh:
    docker exec -it mongo-rs mongosh
Inside the shell:
    rs.initiate()
You should see an output like:
{
  ok: 1,
  ...
}
Then check status:
    rs.status()
You should now see the node in "stateStr": "PRIMARY".

You now have a single-node replica set, perfect for development with transactions.


REPLICA SET *******************

A replica set in MongoDB is a group of MongoDB servers that maintain the same data set, providing high availability and data redundancy.
It's the core of MongoDB‚Äôs fault tolerance and disaster recovery system.

üß† In Simple Terms
Think of a replica set like a team of MongoDB servers where:
    1. One server is the leader (Primary).
    2. The others are followers (Secondaries) that keep copies of the leader's data.
    3. If the leader goes down, one of the followers automatically becomes the new leader.

üîÅ How a Replica Set Works
üß© Components:
| Role          | Description                                                                |
| ------------- | -------------------------------------------------------------------------- |
| **Primary**   | The only node that receives write operations.                              |
| **Secondary** | Copies data from the primary and can serve read requests (optional).       |
| **Arbiter**   | Participates in elections but holds no data. Used to break ties in voting. |

üîÑ Synchronization
    1. Secondaries continuously replicate the oplog (operation log) from the Primary.
    2. Ensures real-time synchronization of data across the replica set.

üìä Example Setup
Replica Set: rs0

+------------------+
|   Primary (A)    |  ‚Üê Receives all writes
+------------------+
         ‚Üì
+------------------+        +------------------+
| Secondary (B)    |  ‚Üê Reads / backup / failover
+------------------+        +------------------+
         ‚Üì
+------------------+
| Arbiter (C)      |  ‚Üê Votes in election (no data)
+------------------+

üîß Setting Up a Replica Set (Local Example)
1. Start 3 MongoDB instances with --replSet rs0.
2. Connect to one with mongosh.
3. Run:
    rs.initiate({
        _id: "rs0",
        members: [
            { _id: 0, host: "localhost:27017" },
            { _id: 1, host: "localhost:27018" },
            { _id: 2, host: "localhost:27019" }
        ]
    });

REPLICA SET *******************

üß± Part 8: MongoDB Schema Design Patterns
MongoDB is schema-less, but how you structure your documents makes a huge difference in performance, scalability, and maintainability.

Let‚Äôs understand the two main approaches and when to use which.

üèóÔ∏è 1. Embedding (Denormalization) - You embed related data inside the same document.

üì¶ Example:
{
  _id: ObjectId("..."),
  name: "Abhishek",
  posts: [
    { title: "MongoDB Basics", content: "..." },
    { title: "Transactions in MongoDB", content: "..." }
  ]
}

‚úÖ Pros:
    1. One read ‚Üí Gets everything
    2. Great performance
    3. Fewer joins or $lookups

‚ùå Cons:
    1. Can hit document size limit (16MB)
    2. Data duplication if used improperly
    3. Harder to update subdocuments in bulk

üß† Use Embedding When:
    1. Data is accessed together
    2. 1:1 or 1:few relationship
    3. Subdocuments are small and bounded in number
    4. Example: Author + Posts (if < 10 posts), Product + Variants, User + Addresses


üîó 2. Referencing (Normalization) - Store references to related documents using ObjectIds.

Example
// authors
{ _id: ObjectId("a1"), name: "Hansraj" }

// posts
{
  title: "Learning MongoDB",
  author_id: ObjectId("a1")
}
Use $lookup in aggregation to join data when needed.

‚úÖ Pros:
    1. Keeps documents smaller
    2.  Avoids data duplication
    3. Better for unbounded relationships

‚ùå Cons:
    1. Needs multiple queries or $lookup
    2. Slower if many joins
    3. No built-in foreign key constraints

üß† Use Referencing When:
    1. Data is accessed separately
    2. 1:many or many:many relationships
    3. Subdocuments can grow unbounded
    4. Example: Blog posts + Comments, Orders + Products

üß™ Schema Design Patterns in MongoDB
MongoDB gives you flexibility, but how you use it determines performance. 
Below are the most important design patterns used by experienced engineers:

üîπ 1. Subset Pattern
Store only the most relevant or recent subset of related data inside the parent document, and keep the full set in a separate collection.

üì¶ Example:
// blog post with subset of recent comments
{
  _id: ObjectId("post1"),
  title: "MongoDB Patterns",
  recent_comments: [
    { user: "Avi", text: "Awesome!" },
    { user: "Neha", text: "Very helpful." }
  ]
}

And the full comment list in another collection:
// full comments stored separately
{ post_id: ObjectId("post1"), user: "Avi", text: "Awesome!", timestamp: ... }

‚úÖ Pros:
    1. Fast read for UI (only recent comments)
    2. Compact main document
    3. Full history available when needed

‚ùå Cons:
    1. Slightly more complex write logic (insert in both places)
    2. Needs logic to keep the subset updated



üîπ 2. Extended Reference Pattern
Store a reference to a related document, plus some frequently-used fields, to avoid $lookup.

‚úÖ Use Case:
You show user profile names along with their posts. You don't want a join every time.

{
  _id: ObjectId("post1"),
  title: "Hello MongoDB",
  author_id: ObjectId("user123"),
  author_name: "Abhishek"
}
So your UI can show both post and name without join.

‚úÖ Pros:
    1. Improves read performance (no $lookup)
    2. Avoids unnecessary DB calls

‚ùå Cons:
    1. Denormalization = duplication
    2. If name changes, you must update all posts (or use background job)



üîπ 3. Outlier Pattern
Move large or rarely-used subdocuments to a separate collection to keep documents slim and fast.

‚úÖ Use Case:
You store a user with preferences, bio, recent activities, etc., but only access preferences once in a while.

üì¶ Example:
Main document:
{
  _id: ObjectId("user1"),
  name: "Hansraj",
  email: "h@abc.com"
}

Outlier stored separately:
{
  user_id: ObjectId("user1"),
  preferences: {
    theme: "dark",
    notifications: true
  }
}

‚úÖ Pros:
    1. Keeps hot data small and fast
    2. Better performance
    3. Avoids hitting 16MB doc limit

‚ùå Cons:
    1. Requires a join or second query to fetch full profile

üîπ 4. Polymorphic Pattern
Store different types of related data in the same collection using a type field.

‚úÖ Use Case:
Logging system: one collection for API logs, DB logs, and auth logs.

üì¶ Example:
// single collection: logs
{
  type: "api",
  endpoint: "/login",
  method: "POST",
  timestamp: ...
}
{
  type: "db",
  operation: "insert",
  collection: "users",
  timestamp: ...
}

‚úÖ Pros:
    1. Single query interface for multiple types
    2. Easier aggregation

‚ùå Cons:
    1. Fields may vary per doc
    2. Schema validation is harder

üéØ How to Decide Which Pattern to Use?
Ask yourself:
    1. How frequently is the sub-data accessed?
    2. Is the relationship bounded (1-10 items) or unbounded (unlimited)?
    3. Do I need all of it together or only some parts often?
    4. What‚Äôs the impact on read/write performance?
    5. What is the access pattern on the frontend?


üöÄ Part 11: MongoDB Performance Tips & Monitoring

üß† 1. Indexing: Your #1 Performance Tool
‚úÖ Use Indexes!
MongoDB uses indexes to avoid scanning all documents (COLLSCAN). 
Always index fields used in:
    1. Queries (find)
    2. Sorts
    3. Filters
    4. Joins ($lookup)
    5. Range queries

üîç Check which index is used
db.collection.find({ name: "Abhishek" }).explain("executionStats")

üß† Tip:
Use compound indexes when you query by multiple fields:
db.users.createIndex({ age: 1, city: 1 })

But:
    1. Order matters
    2. Index on { age: 1, city: 1 } supports:
        1. ‚úÖ { age: 25 }
        2. ‚úÖ { age: 25, city: "Delhi" }
        3. ‚ùå { city: "Delhi" } (age is missing)

üß† 2. Query Optimization

‚úÖ Use projections:
db.users.find({}, { name: 1, _id: 0 })
Returns only required fields ‚Äî saves bandwidth and memory.

‚úÖ Avoid $where or regex without index ‚Äî they‚Äôre slow.
‚úÖ Always profile your slow queries with:
db.setProfilingLevel(1) // log slow ops
db.system.profile.find().sort({ millis: -1 }).limit(5)

üß† 3. Avoid Collection Scans
Use explain() to find:
executionStats.executionStages.stage
If you see "COLLSCAN" ‚Üí you're missing an index

üß† 4. Use Capped Collections for Logs
If you‚Äôre storing logs or events:
db.createCollection("logs", { capped: true, size: 10485760 })
MongoDB will auto-delete old docs once the cap is hit.

üß† 5. Use Aggregation Carefully
    1. Avoid huge $group or $lookup without indexes
    2. Use $project early to discard unused fields
    3. Use $merge to store large results into temp collections

üìä 6. Monitoring MongoDB (Tools)
üíª A. mongostat
> mongostat --port 27017

Shows live stats like:
    1. Ops/sec
    2. Connections
    3. Memory usage
    4. Lock %

üìà B. mongotop
> mongotop
Shows time spent reading/writing per collection.

üîç C. Use db.serverStatus()
Shows:
    1. Memory stats
    2. Connections
    3. Cursors
    4. WiredTiger cache usage
    5. Index usage

üõ†Ô∏è Bonus Performance Tips
| üîß Tip                                       | ‚úÖ Why It Helps                 |
| -------------------------------------------- | ------------------------------ |
| Avoid large docs > 16MB                      | MongoDB max doc size is 16MB   |
| Use pagination with `.limit()` and `.skip()` | Avoids loading too much data   |
| Pre-aggregate frequently accessed data       | Caches results, saves CPU      |
| Monitor replica lag                          | To detect slow secondaries     |
| Avoid too many indexes                       | Each write updates all indexes |
| Shard large collections early                | Don't wait until it's too late |

üö® Red Flags to Watch Out For
    1. COLLSCAN in explain() output
    2. WiredTiger cache over 80%
    3. Replica lag > few seconds
    4. opcounters.insert/query/update/delete too high
    5. MongoDB logs showing page faults, write lock, OOM



